package events

import (
	"fmt"
	"time"

	"github.com/flanksource/commons/collections/set"
	"github.com/flanksource/commons/logger"
	"github.com/flanksource/duty/upstream"
	"github.com/flanksource/incident-commander/api"
	"github.com/jackc/pgx/v5/pgxpool"
	"gorm.io/gorm"
)

const (
	// eventMaxAttempts is the maximum number of attempts to process an event in `event_queue`
	eventMaxAttempts = 3

	// eventQueueUpdateChannel is the channel on which new events on the `event_queue` table
	// are notified.
	eventQueueUpdateChannel = "event_queue_updates"
)

type (
	// AsyncEventHandler processes multiple events and returns the failed ones
	AsyncEventHandler func(*api.Context, []api.Event) []api.Event

	// SyncEventHandler processes a single event and ONLY makes db changes.
	SyncEventHandler func(*api.Context, api.Event) error
)

// List of all sync events in the `event_queue` table.
//
// These events are generated by the database in response to updates on some of the tables.
const (
	EventTeamUpdate = "team.update"
	EventTeamDelete = "team.delete"

	EventCheckPassed = "check.passed"
	EventCheckFailed = "check.failed"

	EventComponentStatusHealthy   = "component.status.healthy"
	EventComponentStatusUnhealthy = "component.status.unhealthy"
	EventComponentStatusInfo      = "component.status.info"
	EventComponentStatusWarning   = "component.status.warning"
	EventComponentStatusError     = "component.status.error"

	EventNotificationUpdate = "notification.update"
	EventNotificationDelete = "notification.delete"

	EventIncidentCommentAdded        = "incident.comment.added"
	EventIncidentCreated             = "incident.created"
	EventIncidentDODAdded            = "incident.dod.added"
	EventIncidentDODPassed           = "incident.dod.passed"
	EventIncidentDODRegressed        = "incident.dod.regressed"
	EventIncidentResponderAdded      = "incident.responder.added"
	EventIncidentResponderRemoved    = "incident.responder.removed"
	EventIncidentStatusCancelled     = "incident.status.cancelled"
	EventIncidentStatusClosed        = "incident.status.closed"
	EventIncidentStatusInvestigating = "incident.status.investigating"
	EventIncidentStatusMitigated     = "incident.status.mitigated"
	EventIncidentStatusOpen          = "incident.status.open"
	EventIncidentStatusResolved      = "incident.status.resolved"
)

// List of async events.
//
// Async events require the handler to talk to 3rd party services.
// They are not determinant and cannot be reliably rolled back and retried.
//
// They are mostly generated by the application itself from sync consumers in response
// to a sync event.
// Or, they could also be generated by the database.
const (
	EventPushQueueCreate = "push_queue.create"

	EventNotificationSend = "notification.send"

	EventJiraResponderAdded = "incident.responder.jira.added"
	EventJiraCommentAdded   = "incident.comment.jira.added"

	EventMSPlannerResponderAdded = "incident.responder.msplanner.added"
	EventMSPlannerCommentAdded   = "incident.comment.msplanner.added"
)

type Config struct {
	UpstreamPush upstream.UpstreamConfig
}

// syncConsumerWatchEvents keeps a registry of all the event_queue consumer and the events they watch.
// This helps in ensuring that a single event is not being consumed by multiple consumers.
var syncConsumerWatchEvents = map[string][]string{
	"team":  {EventTeamUpdate, EventTeamDelete},
	"check": {EventCheckPassed, EventCheckFailed},
	"component": {
		EventComponentStatusError,
		EventComponentStatusHealthy,
		EventComponentStatusInfo,
		EventComponentStatusUnhealthy,
		EventComponentStatusWarning,
	},
	"incident.responder": {EventIncidentResponderAdded},
	"incident.comment":   {EventIncidentCommentAdded},
	"notification_update": {
		EventNotificationUpdate, EventNotificationDelete,
	},
	"notification_add": {
		EventIncidentCreated,
		EventIncidentDODAdded,
		EventIncidentDODPassed,
		EventIncidentDODRegressed,
		EventIncidentResponderRemoved,
		EventIncidentStatusCancelled,
		EventIncidentStatusClosed,
		EventIncidentStatusInvestigating,
		EventIncidentStatusMitigated,
		EventIncidentStatusOpen,
		EventIncidentStatusResolved,
	},
}

var asyncConsumerWatchEvents = map[string][]string{
	"push_queue":        {EventPushQueueCreate},
	"notification_send": {EventNotificationSend},
	"incident.responder": {
		EventJiraResponderAdded, EventMSPlannerResponderAdded,
		EventMSPlannerCommentAdded, EventJiraCommentAdded,
	},
}

func StartConsumers(gormDB *gorm.DB, pgpool *pgxpool.Pool, config Config) {
	uniqWatchEvents := set.New[string]()
	for _, v := range syncConsumerWatchEvents {
		for _, e := range v {
			if uniqWatchEvents.Contains(e) {
				logger.Fatalf("Error starting consumers: event[%s] has multiple consumers", e)
			}

			uniqWatchEvents.Add(e)
		}
	}

	for _, v := range asyncConsumerWatchEvents {
		for _, e := range v {
			if uniqWatchEvents.Contains(e) {
				logger.Fatalf("Error starting consumers: event[%s] has multiple consumers", e)
			}

			uniqWatchEvents.Add(e)
		}
	}

	allConsumers := []*EventConsumer{
		NewTeamConsumerSync(gormDB, pgpool),
		NewCheckConsumerSync(gormDB, pgpool),
		NewComponentConsumerSync(gormDB, pgpool),
		NewResponderConsumerSync(gormDB, pgpool),
		NewCommentConsumerSync(gormDB, pgpool),
		NewNotificationConsumerSync(gormDB, pgpool),
		NewNotificationUpdatesConsumerSync(gormDB, pgpool),

		// Async consumers
		NewNotificationSendConsumerAsync(gormDB, pgpool),
		NewResponderConsumerAsync(gormDB, pgpool),
	}
	if config.UpstreamPush.Valid() {
		allConsumers = append(allConsumers, NewUpstreamPushConsumerAsync(gormDB, pgpool, config))
	}

	for i := range allConsumers {
		go allConsumers[i].Listen()
	}
}

// fetchEvents fetches given watch events from the `event_queue` table.
func fetchEvents(ctx *api.Context, watchEvents []string, batchSize int) ([]api.Event, error) {
	const selectEventsQuery = `
			DELETE FROM event_queue
			WHERE id IN (
				SELECT id FROM event_queue
				WHERE 
					attempts <= @maxAttempts AND
					name IN @events AND
					(last_attempt IS NULL OR last_attempt <= NOW() - INTERVAL '1 SECOND' * @baseDelay * POWER(attempts, @exponential))
				ORDER BY priority DESC, created_at ASC
				FOR UPDATE SKIP LOCKED
				LIMIT @batchSize
			)
			RETURNING *
		`

	var events []api.Event
	vals := map[string]any{
		"maxAttempts": eventMaxAttempts,
		"events":      watchEvents,
		"batchSize":   batchSize,
		"baseDelay":   60, // in seconds
		"exponential": 5,  // along with baseDelay = 60, the retries are 1, 6, 31, 156 (in minutes)
	}
	err := ctx.DB().Raw(selectEventsQuery, vals).Scan(&events).Error
	if err != nil {
		return nil, fmt.Errorf("error selecting events: %w", err)
	}

	return events, nil
}

// newEventQueueAsyncConsumerFunc returns a new event consumer for the `watchEvents` events in the `event_queue` table.
func newEventQueueAsyncConsumerFunc(watchEvents []string, handleEventsAsync AsyncEventHandler) EventConsumerFunc {
	return func(ctx *api.Context, batchSize int) error {
		tx := ctx.DB().Begin()
		if tx.Error != nil {
			return fmt.Errorf("error initiating db tx: %w", tx.Error)
		}
		defer tx.Rollback()

		ctx = ctx.WithDB(tx)

		events, err := fetchEvents(ctx, watchEvents, batchSize)
		if err != nil {
			return fmt.Errorf("error fetching events: %w", err)
		}

		if len(events) == 0 {
			return api.Errorf(api.ENOTFOUND, "No events found")
		}

		failedEvents := handleEventsAsync(ctx, events)
		saveFailedEvents(tx, failedEvents)

		return tx.Commit().Error
	}
}

// newEventQueueConsumerFunc returns a new sync event consumer for the `watchEvents` events in the `event_queue` table.
func newEventQueueSyncConsumerFunc(watchEvents []string, syncConsumers ...SyncEventHandler) EventConsumerFunc {
	return func(ctx *api.Context, batchSize int) error {
		tx := ctx.DB().Begin()
		if tx.Error != nil {
			return fmt.Errorf("error initiating db tx: %w", tx.Error)
		}
		defer tx.Rollback()

		events, err := fetchEvents(ctx.WithDB(tx), watchEvents, batchSize)
		if err != nil {
			return fmt.Errorf("error fetching events: %w", err)
		}

		if len(events) == 0 {
			return api.Errorf(api.ENOTFOUND, "No events found")
		}

		failedEvents := handleEventsSync(ctx, events, syncConsumers)
		saveFailedEvents(tx, failedEvents)

		return tx.Commit().Error
	}
}

// handleEventsSync runs all the sync consumers for the given events.
//
// Each event is handled in isolation (in a separate transaction).
func handleEventsSync(ctx *api.Context, events []api.Event, syncConsumers []SyncEventHandler) []api.Event {
	failedEvents := make([]api.Event, 0, len(events))
	for i := range events {
		if err := processSyncConsumers(ctx, events[i], syncConsumers); err != nil {
			logger.Errorf("Failed to process event[%s]: %s", events[i].ID, err.Error())
			events[i].Error = err.Error()
			failedEvents = append(failedEvents, events[i])
		}
	}

	return failedEvents
}

// processSyncConsumers runs all the sync consumers for the given event.
//
// All of the consumers are expected to succeed.
// Returns error even if a single consumer fails and any changes are rolled back.
func processSyncConsumers(ctx *api.Context, event api.Event, syncConsumers []SyncEventHandler) error {
	tx := ctx.DB().Begin()
	if tx.Error != nil {
		return fmt.Errorf("error initiating db tx: %w", tx.Error)
	}
	defer tx.Rollback()

	for _, syncConsumer := range syncConsumers {
		if err := syncConsumer(ctx, event); err != nil {
			return fmt.Errorf("error processing sync consumer: %w", err)
		}
	}

	return tx.Commit().Error
}

// saveFailedEvents saves failed events back to the `event_queue` table.
func saveFailedEvents(tx *gorm.DB, failedEvents []api.Event) {
	lastAttempt := time.Now()

	for i := range failedEvents {
		e := &failedEvents[i]
		e.Attempts += 1
		e.LastAttempt = &lastAttempt
		logger.Errorf("Failed to process event[%s]: %s", e.ID, e.Error)
	}

	if len(failedEvents) > 0 {
		if err := tx.Create(failedEvents).Error; err != nil {
			// TODO: More robust way to handle failed event insertion failures
			logger.Errorf("Error inserting into table:event_queue with error:%v. %v", err)
		}
	}
}
